{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI-Book-Recommender: Main Pipeline\n",
    "This notebook integrates the entire AI-Book-Recommender pipeline, including data loading, preprocessing, model development, evaluation, visualization, and a Streamlit-based web interface for interactive book recommendations.\n",
    "\n",
    "## Overview\n",
    "- **Data Loading and Cleaning**: Load and preprocess books, users, and ratings datasets.\n",
    "- **Exploratory Data Analysis (EDA)**: Visualize rating distributions, top books, and user activity.\n",
    "- **Recommendation Models**: Implement popularity-based, content-based, collaborative filtering (SVD), and hybrid recommenders.\n",
    "- **Evaluation**: Assess model performance using RMSE.\n",
    "- **Visualization**: Generate heatmaps, PCA plots, and other insights.\n",
    "- **Streamlit Interface**: Deploy an interactive web app for users to explore recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse.linalg import svds\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.decomposition import PCA\n",
    "import streamlit as st\n",
    "\n",
    "# Set seaborn style\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Ensure plots appear inline in Jupyter\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess datasets\n",
    "def load_and_preprocess_data():\n",
    "    # Load datasets\n",
    "    books = pd.read_csv('books.csv', low_memory=False)\n",
    "    users = pd.read_csv('users.csv')\n",
    "    ratings = pd.read_csv('ratings.csv')\n",
    "\n",
    "    # Clean Books Dataset\n",
    "    books.drop_duplicates(subset='ISBN', inplace=True)\n",
    "    books.dropna(subset=['ISBN', 'Book-Title', 'Book-Author'], inplace=True)\n",
    "    books['Publisher'].fillna('Unknown', inplace=True)\n",
    "    books['Book-Title'] = books['Book-Title'].fillna('')\n",
    "\n",
    "    # Clean Users Dataset\n",
    "    users.drop_duplicates(subset='User-ID', inplace=True)\n",
    "    users.loc[(users['Age'] < 5) | (users['Age'] > 100), 'Age'] = np.nan\n",
    "    users['Age'].fillna(users['Age'].median(), inplace=True)\n",
    "\n",
    "    # Clean Ratings Dataset\n",
    "    ratings = ratings[ratings['Book-Rating'] > 0]\n",
    "    ratings.drop_duplicates(inplace=True)\n",
    "\n",
    "    return books, users, ratings\n",
    "\n",
    "books, users, ratings = load_and_preprocess_data()\n",
    "\n",
    "# Preview datasets\n",
    "print('Books Dataset:')\n",
    "print(books.head())\n",
    "print('\\nUsers Dataset:')\n",
    "print(users.head())\n",
    "print('\\nRatings Dataset:')\n",
    "print(ratings.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Popularity-Based Recommender\n",
    "def popularity_recommender(ratings, books, top_n=10):\n",
    "    pop_scores = ratings['ISBN'].value_counts().head(top_n).index\n",
    "    return books[books['ISBN'].isin(pop_scores)][['ISBN', 'Book-Title', 'Book-Author', 'Publisher']]\n",
    "\n",
    "# Content-Based Recommender\n",
    "def content_based_recommender(book_title, books, top_n=10):\n",
    "    tfidf = TfidfVectorizer(stop_words='english')\n",
    "    tfidf_matrix = tfidf.fit_transform(books['Book-Title'])\n",
    "    cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "    indices = pd.Series(books.index, index=books['Book-Title']).drop_duplicates()\n",
    "    idx = indices[book_title]\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)[1:top_n+1]\n",
    "    book_indices = [i[0] for i in sim_scores]\n",
    "    return books.iloc[book_indices][['ISBN', 'Book-Title', 'Book-Author', 'Publisher']]\n",
    "\n",
    "# Collaborative Filtering with SVD\n",
    "def svd_recommender(ratings, user_id, books, top_n=10, k=50):\n",
    "    user_item_matrix = ratings.pivot(index='User-ID', columns='ISBN', values='Book-Rating').fillna(0)\n",
    "    user_ratings_mean = user_item_matrix.mean(axis=1)\n",
    "    R_demeaned = user_item_matrix.sub(user_ratings_mean, axis=0)\n",
    "    U, sigma, Vt = svds(R_demeaned, k=k)\n",
    "    sigma = np.diag(sigma)\n",
    "    all_user_predicted_ratings = np.dot(np.dot(U, sigma), Vt) + user_ratings_mean.values.reshape(-1, 1)\n",
    "    preds_df = pd.DataFrame(all_user_predicted_ratings, columns=user_item_matrix.columns, index=user_item_matrix.index)\n",
    "    sorted_user_predictions = preds_df.loc[user_id].sort_values(ascending=False)\n",
    "    user_data = ratings[ratings['User-ID'] == user_id]['ISBN'].values\n",
    "    recommendations = sorted_user_predictions[~sorted_user_predictions.index.isin(user_data)].head(top_n)\n",
    "    return books[books['ISBN'].isin(recommendations.index)][['ISBN', 'Book-Title', 'Book-Author', 'Publisher']]\n",
    "\n",
    "# Hybrid Recommender\n",
    "def hybrid_recommender(user_id, book_title, ratings, books, top_n=10):\n",
    "    print('Content-Based:')\n",
    "    print(content_based_recommender(book_title, books, top_n))\n",
    "    print('\\nCollaborative Filtering:')\n",
    "    print(svd_recommender(ratings, user_id, books, top_n))\n",
    "    print('\\nPopularity-Based:')\n",
    "    print(popularity_recommender(ratings, books, top_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation\n",
    "def evaluate_split_small(ratings, sample_size=1000):\n",
    "    sample = ratings.sample(n=sample_size, random_state=42)\n",
    "    train, test = train_test_split(sample, test_size=0.2, random_state=42)\n",
    "    common_users = list(set(train['User-ID']) & set(test['User-ID']))\n",
    "    \n",
    "    if len(common_users) == 0:\n",
    "        print('No common users between train and test. Increase sample size.')\n",
    "        return\n",
    "    \n",
    "    train = train[train['User-ID'].isin(common_users)]\n",
    "    test = test[test['User-ID'].isin(common_users)]\n",
    "    \n",
    "    train_matrix = train.pivot(index='User-ID', columns='ISBN', values='Book-Rating').fillna(0)\n",
    "    if train_matrix.shape[0] < 2 or train_matrix.shape[1] < 2:\n",
    "        print('Not enough data for SVD.')\n",
    "        return\n",
    "    \n",
    "    user_ratings_mean = train_matrix.mean(axis=1)\n",
    "    R_demeaned = train_matrix.sub(user_ratings_mean, axis=0)\n",
    "    U, sigma, Vt = svds(R_demeaned, k=50)\n",
    "    sigma = np.diag(sigma)\n",
    "    predicted_ratings = np.dot(np.dot(U, sigma), Vt) + user_ratings_mean.values.reshape(-1, 1)\n",
    "    preds_df = pd.DataFrame(predicted_ratings, columns=train_matrix.columns, index=train_matrix.index)\n",
    "    \n",
    "    actual = []\n",
    "    predicted = []\n",
    "    for _, row in test.iterrows():\n",
    "        user = row['User-ID']\n",
    "        isbn = row['ISBN']\n",
    "        if user in preds_df.index and isbn in preds_df.columns:\n",
    "            actual.append(row['Book-Rating'])\n",
    "            predicted.append(preds_df.loc[user, isbn])\n",
    "    \n",
    "    if len(actual) > 0:\n",
    "        rmse = sqrt(mean_squared_error(actual, predicted))\n",
    "        print(f'Actual RMSE (small sample): {rmse}')\n",
    "    else:\n",
    "        print('No valid predictions to compute RMSE.')\n",
    "\n",
    "evaluate_split_small(ratings, sample_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizations\n",
    "def visualize_data(ratings, books, users):\n",
    "    # Distribution of book ratings\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.histplot(ratings['Book-Rating'], bins=10, kde=False, color='skyblue')\n",
    "    plt.title('Distribution of Book Ratings', fontsize=14)\n",
    "    plt.xlabel('Rating')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(range(0, 11))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Top 10 most rated books\n",
    "    popular_counts = ratings['ISBN'].value_counts().head(10).reset_index()\n",
    "    popular_counts.columns = ['ISBN', 'Rating Count']\n",
    "    popular_titles = books[['ISBN', 'Book-Title']]\n",
    "    popular_books = pd.merge(popular_counts, popular_titles, on='ISBN', how='left')\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(x='Rating Count', y='Book-Title', data=popular_books, palette='viridis')\n",
    "    plt.title('Top 10 Most Rated Books')\n",
    "    plt.xlabel('Number of Ratings')\n",
    "    plt.ylabel('Book Title')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # User Age Distribution\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.boxplot(x=users['Age'], color='lightgreen')\n",
    "    plt.title('User Age Distribution (Boxplot)')\n",
    "    plt.xlabel('Age')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Heatmap of Top 50 Users vs Top 50 Books\n",
    "    top_50_users = ratings['User-ID'].value_counts().head(50).index\n",
    "    top_50_books = ratings['ISBN'].value_counts().head(50).index\n",
    "    ratings_heatmap = ratings[ratings['User-ID'].isin(top_50_users) & ratings['ISBN'].isin(top_50_books)]\n",
    "    heatmap_matrix = ratings_heatmap.pivot(index='User-ID', columns='ISBN', values='Book-Rating')\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    sns.heatmap(heatmap_matrix, cmap='YlGnBu', cbar_kws={'label': 'Rating'})\n",
    "    plt.title('Heatmap of Ratings: Top 50 Users vs Top 50 Books')\n",
    "    plt.xlabel('Book ISBN')\n",
    "    plt.ylabel('User ID')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # SVD Visualization with PCA\n",
    "    top_users = ratings['User-ID'].value_counts().head(1000).index\n",
    "    top_books = ratings['ISBN'].value_counts().head(1000).index\n",
    "    ratings_small = ratings[ratings['User-ID'].isin(top_users) & ratings['ISBN'].isin(top_books)]\n",
    "    user_item_matrix = ratings_small.pivot(index='User-ID', columns='ISBN', values='Book-Rating').fillna(0)\n",
    "    user_ratings_mean = user_item_matrix.mean(axis=1)\n",
    "    R_demeaned = user_item_matrix.sub(user_ratings_mean, axis=0)\n",
    "    U, sigma, Vt = svds(R_demeaned, k=50)\n",
    "    pca = PCA(n_components=2)\n",
    "    user_pca = pca.fit_transform(U)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(user_pca[:, 0], user_pca[:, 1], alpha=0.5)\n",
    "    plt.title('User Visualization in SVD-Reduced Space via PCA')\n",
    "    plt.xlabel('PC1')\n",
    "    plt.ylabel('PC2')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "visualize_data(ratings, books, users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Streamlit Interface\n",
    "def run_streamlit_app():\n",
    "    st.title('AI-Book-Recommender')\n",
    "    st.write('Discover personalized book recommendations using collaborative filtering, content-based filtering, and popularity-based methods.')\n",
    "\n",
    "    # User ID selection\n",
    "    user_id = st.selectbox('Select User ID:', ratings['User-ID'].unique())\n",
    "\n",
    "    # Book title selection\n",
    "    book_title = st.selectbox('Select Book Title:', books['Book-Title'].unique())\n",
    "\n",
    "    # Show recommendations\n",
    "    if st.button('Show Recommendations'):\n",
    "        st.write('### Recommendations')\n",
    "        st.write('#### Content-Based:')\n",
    "        st.dataframe(content_based_recommender(book_title, books))\n",
    "        st.write('#### Collaborative Filtering:')\n",
    "        st.dataframe(svd_recommender(ratings, user_id, books))\n",
    "        st.write('#### Popularity-Based:')\n",
    "        st.dataframe(popularity_recommender(ratings, books))\n",
    "\n",
    "    # Evaluate model\n",
    "    if st.button('Evaluate RMSE'):\n",
    "        st.write('### Model Evaluation')\n",
    "        evaluate_split_small(ratings, sample_size=1000)\n",
    "\n",
    "# Note: Run `streamlit run main.py` in terminal to launch the app\n",
    "# This cell is for demonstration; actual Streamlit app requires a .py file\n",
    "print('To run the Streamlit app, save this code as main.py and execute: streamlit run main.py')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}